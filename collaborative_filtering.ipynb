{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7e8f8a38-5ef1-416a-8e55-fa383bff04ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n",
      "       user_id  item_id  rating  timestamp\n",
      "99995      880      476       3  880175444\n",
      "99996      716      204       5  879795543\n",
      "99997      276     1090       1  874795795\n",
      "99998       13      225       2  882399156\n",
      "99999       12      203       3  879959583\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Evaluate user-user and item-item collaborative filtering using the MovieLens 100K dataset,  \n",
    "# which contains 100,000 ratings from 943 users on 1,682 movies.\n",
    "# Load the dataset 'u_data.csv' file from working directory after download.\n",
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data = pd.read_csv('u.data', sep='\\t', names=columns)\n",
    "\n",
    "# The csv contains four columns of data: \n",
    "# --user_id – the unique identification number assigned to each movie goer/movie reviewer.\n",
    "# --item_id – the unique identification number assigned to each movie that has been reviewed or rated.\n",
    "# --rating – the rating assigned by a movie reviewer to a movie on a scale of 1 to 5.\n",
    "# --timestamp – Unix timestamp (date and time) for when the movie was rated. \n",
    "# The full data set is 10,000 rows with each row holding a movie reviewer's ID number, \n",
    "# the ID number of the movie reviewed, the rating of the movie between 1 and 5, the timestamp of the review.\n",
    "\n",
    "# Check the dataset structure\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3b8d4080-888a-46b5-a698-5441e6363201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Matrix shape: (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create Ratings Matrix\n",
    "# Create a user-item matrix dataframe from csv data.\n",
    "# The csv data is converted into a basic ratings matrix or “user_item_matrix” using the pivot function \n",
    "# and missing values are filled with NaN. The pivot function constructs a new dataframe with movie \n",
    "# reviewer IDs (user_ids) along the index or y-axis as rows, movie IDs (item_ids) along the upper \n",
    "# x-axis as columns, and movie ratings (rating) as the actual values in the matrix.\n",
    "user_item_matrix = data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
    "\n",
    "# Convert non-numeric dataframe into numeric numpy array (or matrix) for later work with machine learning algorithms.\n",
    "# Each column is an item rating vector  that can be used in item-item collaborative filtering\n",
    "#    in which users similar to a target user are sought in order to make predictions about the target user.\n",
    "# Each row is a user rating vector that can be used in user-user collaborative filtering\n",
    "#    in which items similar to a target item are sought in order to make predictions about the target item.\n",
    "user_item_matrix = user_item_matrix.values\n",
    "\n",
    "# Check shape. The matrix is now of m x n dimensions with m rows of users or number of movie reviewers (num_users) \n",
    "# and n colummns of rated movies. \n",
    "print(\"User-Item Matrix shape:\", user_item_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8ed040f1-8df5-411d-b04c-8b5e6c8ce054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Matrix shape: (943, 20)\n"
     ]
    }
   ],
   "source": [
    "# Ratings Matrix Factorization\n",
    "# Import modules and specific algorithm for Singular Value Decomposition (SVD) matrix decomposition or factorization\n",
    "# The original user_item_matrix with m users and n movie items is factorized into three smaller matrices:\n",
    "#                 user_item_matrix ≈ User Matrix (m x k) * Latent Feature Matrix (k x k) * Item Matrix (k x n)\n",
    "# --User Matrix of dimensions m x k with m movie reviewer rows and k latent feature columns. \n",
    "# --Latent Feature Matrix of dimensions k x k as a diagonal matrix of the top most important k latent features.\n",
    "# --Item Matrix of dimensions k x n with k latent feature rows and n rated movie columns.\n",
    "\n",
    "# Latent features are hidden patterns or abstract concepts in the data that explain the relationships \n",
    "# between users and items in a recommendation system. They are not explicitly present in the dataset \n",
    "# but are derived mathematically during techniques like SVD.\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Create an model instance of the TruncatedSVD class.\n",
    "# Decompose or factorize with SVD.\n",
    "# Set the number of derived latent features or components (n_components) to 20.\n",
    "# This is the number of latent factors or features that will be retained when performing dimensionality reduction.\n",
    "# The arbitrary value of \"20\" is selected based on experimentation or heuristics to balance model complexity and performance.\n",
    "# Higher n_components values capture more variance but may lead to overfitting or computational inefficiency, \n",
    "# while lower values may oversimplify the data.\n",
    "svd = TruncatedSVD(n_components=20)\n",
    "\n",
    "# Fit the model instance to the ratings matrix, \"user_item_matrix\" \n",
    "user_latent_matrix = svd.fit_transform(user_item_matrix)\n",
    "# The resulting latent_matrix represents a version of the original user_item_matrix that has been transformed by the SVD model \n",
    "# into a reduced-dimensional format with dimensions (num_users, n_components).\n",
    "# This new matrix contains the user representations in the latent feature space, a compressed space that captures \n",
    "# important patterns in the data.\n",
    "# Each row corresponds to a user or movie rewiewer, and each column represents a latent feature (one of the 20 n_components).\n",
    "\n",
    "# Show shape of reduced-dimension, latent feature space version of original rating matrix\n",
    "print(\"Latent Matrix shape:\", user_latent_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4cc52189-dd4b-4b9b-b22a-60264c64a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reduced-dimension, latent feature space version of original rating matrix for user-user collaborative filtering \n",
    "# Function to recommend items based on user-user similarity\n",
    "def recommend_for_user(user_id, user_latent_matrix, user_similarity, top_n=20): # top_n similar users\n",
    "    \"\"\"\n",
    "    Finds users similar to a given target user based on cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id: The ID of the user to find similarities for.\n",
    "    - user_latent_matrix: Matrix of latent features for all users.\n",
    "    - top_n: Number of similar users to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of IDs of the top_n most similar users.\n",
    "    \"\"\"\n",
    "    # Find the most similar users\n",
    "    similar_users = np.argsort(user_similarity[user_id])[-top_n-1:-1]  # Exclude self (last user in sorted array)\n",
    "    \n",
    "    # Get the ratings of the most similar users (example)\n",
    "    user_ratings = np.zeros(user_latent_matrix.shape[1])  # Placeholder for ratings across items\n",
    "    for similar_user in similar_users:\n",
    "        user_ratings += user_latent_matrix[similar_user]  # Aggregate ratings from similar users\n",
    "    \n",
    "    # Rank the items and recommend the top ones\n",
    "    recommended_items = np.argsort(user_ratings)[-top_n:]  # Get the top N items\n",
    "    return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae60e03f-2927-42b4-9a7e-6a86e39a16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended items for User 34 using cosine similarity:\n",
      "- GoldenEye (1995)\n",
      "- Four Rooms (1995)\n",
      "- Get Shorty (1995)\n",
      "- Seven (Se7en) (1995)\n",
      "Recommended items for User 34 using centered cosine similarity:\n",
      "- GoldenEye (1995)\n",
      "- Four Rooms (1995)\n",
      "- Get Shorty (1995)\n",
      "- Seven (Se7en) (1995)\n",
      "\n",
      "\n",
      "Recommended items for User 205 using cosine similarity:\n",
      "- GoldenEye (1995)\n",
      "- Four Rooms (1995)\n",
      "- Get Shorty (1995)\n",
      "- Postino, Il (1994)\n",
      "Recommended items for User 205 using centered cosine similarity:\n",
      "- GoldenEye (1995)\n",
      "- Four Rooms (1995)\n",
      "- Get Shorty (1995)\n",
      "- Postino, Il (1994)\n",
      "\n",
      "\n",
      "Recommended items for User 390 using cosine similarity:\n",
      "- Toy Story (1995)\n",
      "- GoldenEye (1995)\n",
      "- Richard III (1995)\n",
      "- Antonia's Line (1995)\n",
      "Recommended items for User 390 using centered cosine similarity:\n",
      "- Toy Story (1995)\n",
      "- GoldenEye (1995)\n",
      "- Seven (Se7en) (1995)\n",
      "- Antonia's Line (1995)\n",
      "\n",
      "\n",
      "Recommended items for User 174 using cosine similarity:\n",
      "- Toy Story (1995)\n",
      "- Usual Suspects, The (1995)\n",
      "- Postino, Il (1994)\n",
      "- Mr. Holland's Opus (1995)\n",
      "Recommended items for User 174 using centered cosine similarity:\n",
      "- Toy Story (1995)\n",
      "- Usual Suspects, The (1995)\n",
      "- Postino, Il (1994)\n",
      "- Mr. Holland's Opus (1995)\n",
      "\n",
      "\n",
      "Recommended items for User 910 using cosine similarity:\n",
      "- Toy Story (1995)\n",
      "- Four Rooms (1995)\n",
      "- Twelve Monkeys (1995)\n",
      "- White Balloon, The (1995)\n",
      "Recommended items for User 910 using centered cosine similarity:\n",
      "- Toy Story (1995)\n",
      "- Four Rooms (1995)\n",
      "- Twelve Monkeys (1995)\n",
      "- From Dusk Till Dawn (1996)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine impact of centered and uncentered cosine similarity on user-user movie recommendations\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get movie names and IDs\n",
    "columns = ['movie id', 'movie title', 'release date', 'video release date',\n",
    "              'IMDb URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "              'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "              'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "              'Thriller', 'War', 'Western'] \n",
    "movie_data = pd.read_csv('u.item', sep='|', names=columns, encoding='ISO-8859-1')\n",
    "\n",
    "# List of user IDs to test\n",
    "numbers = [34, 205, 390, 174, 910]\n",
    "\n",
    "for index, i in enumerate(numbers):   \n",
    "    user_id = i\n",
    "    # Compute cosine similarity between users using latent_matrix from SVD\n",
    "    user_similarity = cosine_similarity(latent_matrix)\n",
    "\n",
    "    # Get the top recommended item IDs for the user\n",
    "    recommended_items = recommend_for_user(user_id, user_latent_matrix, user_similarity, top_n=5)\n",
    "\n",
    "    # Get the movie names corresponding to the recommended movie IDs \n",
    "    recommended_movie_names = movie_data[movie_data['movie id'].isin(recommended_items)]['movie title'].values\n",
    "    \n",
    "    print(f\"Recommended items for User {user_id} using cosine similarity:\")\n",
    "    for movie in recommended_movie_names:\n",
    "        print(f\"- {movie}\")\n",
    "    \n",
    "    # Compute centered cosine similarity between users using the centered latent_matrix\n",
    "    # Center the latent matrix by subtracting the mean rating of each user\n",
    "    mean_user_rating = np.mean(user_latent_matrix, axis=1)  # Calculate mean rating for each user\n",
    "    centered_user_latent_matrix = user_latent_matrix - mean_user_rating[:, np.newaxis]  # Subtract mean from each user's ratings\n",
    "    centered_user_similarity = cosine_similarity(centered_user_latent_matrix)\n",
    "\n",
    "    # Get the top recommended item IDs for the user\n",
    "    centered_recommended_items = recommend_for_user(user_id, centered_user_latent_matrix, centered_user_similarity, top_n=5)\n",
    "\n",
    "    # Get the movie names corresponding to the recommended movie IDs (centered similarity)\n",
    "    centered_recommended_movie_names = movie_data[movie_data['movie id'].isin(centered_recommended_items)]['movie title'].values\n",
    "    \n",
    "    print(f\"Recommended items for User {user_id} using centered cosine similarity:\")\n",
    "    for movie in centered_recommended_movie_names:\n",
    "        print(f\"- {movie}\")\n",
    "    print(f\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "96c071cc-9e5d-4daa-b02b-ef1e377fb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reduced-dimension, latent feature space version of original rating matrix for movie-movie collaborative filtering \n",
    "# Fit the model instance to the ratings matrix, \"user_item_matrix.T\" to create movie_latent_matrix \n",
    "# This time the original ratings matrix is transposed to emphasize movies rather than users\n",
    "movie_latent_matrix = svd.fit_transform(user_item_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4b6c7d69-f51e-4416-9676-70afdb5e41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to find similar movies\n",
    "def find_similar_movies(target_movie_id, latent_matrix, top_n=5):\n",
    "    \"\"\"\n",
    "    Finds movies similar to a given target movie based on cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - target_movie_id: The ID of the movie to find similarities for.\n",
    "    - latent_matrix: Matrix of latent features for all items (movies).\n",
    "    - top_n: Number of similar movies to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of IDs of the top_n most similar movies.\n",
    "    \"\"\"\n",
    "    # Compute cosine similarity between the target movie and all other movies\n",
    "    movie_similarity = cosine_similarity(movie_latent_matrix)  \n",
    "    similarity_scores = movie_similarity[target_movie_id]\n",
    "\n",
    "    # Get indices of top_n most similar movies (excluding the target movie itself)\n",
    "    similar_movie_ids = np.argsort(similarity_scores)[-top_n-1:-1][::-1]  # Sort and exclude the target movie\n",
    "\n",
    "    return similar_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "58f9adf0-2198-4522-9fbc-d3d0efb88e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to Movie ['Doom Generation, The (1995)']: ['Big Night (1996)' 'Love Bug, The (1969)' 'Three Musketeers, The (1993)'\n",
      " 'Addiction, The (1995)' 'Grumpier Old Men (1995)']\n",
      "\n",
      "Movies similar to Movie ['Patton (1970)']: ['Fargo (1996)' 'Godfather, The (1972)' 'Alien (1979)'\n",
      " 'Ruling Class, The (1972)' 'Cutthroat Island (1995)']\n",
      "\n",
      "Movies similar to Movie ['Fear of a Black Hat (1993)']: ['Apollo 13 (1995)' 'Three Colors: White (1994)' 'Jeffrey (1995)'\n",
      " 'Speechless (1994)' 'Rising Sun (1993)']\n",
      "\n",
      "Movies similar to Movie ['Raiders of the Lost Ark (1981)']: ['Sleepless in Seattle (1993)' '12 Angry Men (1957)'\n",
      " 'Young Frankenstein (1974)' 'James and the Giant Peach (1996)'\n",
      " 'Crossfire (1947)']\n",
      "\n",
      "Movies similar to Movie ['Nil By Mouth (1997)']: ['Big Lebowski, The (1998)' 'Half Baked (1998)' 'Dangerous Beauty (1998)'\n",
      " 'Twilight (1998)' 'Mercury Rising (1998)']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of movie IDs to test\n",
    "numbers = [34, 205, 390, 174, 910]\n",
    "\n",
    "for index, i in enumerate(numbers):   \n",
    "    # movie_latent_matrix defined from the SVD step above\n",
    "    target_movie_id = i  # Example target movie\n",
    "    target_movie_name = movie_data[movie_data['movie id'].isin([target_movie_id])]['movie title'].values\n",
    "    top_similar_movies = find_similar_movies(target_movie_id, movie_latent_matrix, top_n=5)\n",
    "    \n",
    "    # Get the movie names corresponding to the recommended similar movie IDs \n",
    "    top_similar_movies = movie_data[movie_data['movie id'].isin(top_similar_movies)]['movie title'].values\n",
    "    \n",
    "    print(f\"Movies similar to Movie {target_movie_name}: {top_similar_movies}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
